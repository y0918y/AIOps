{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzuFjvlBql1R"
      },
      "source": [
        "# 손글씨 인식 Application\n",
        "Colab 환경에서 손글씨 인식 애플리케이션을 만들어봅시다. 애플리케이션 사용자의 유스케이스는 아래와 같습니다.\n",
        "- 사용자는 손글씨 이미지 파일을 업로드할 수 있다.\n",
        "- 사용자는 캔버스에 손글씨를 쓸 수 있다.\n",
        "- 사용자는 텍스트 결과를 확인할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9cTt_jYql1S"
      },
      "source": [
        "## 패키지 및 예제 데이터 다운로드하기\n",
        "python package들을 설치합니다. 예제로 사용할 이미지들도 다운로드 받습니다. Colab에서 실행하지 않는 경우 이 셀은 실행하지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sScMaXDaql1T"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/mrsyee/dl_apps/main/ocr/requirements-colab.txt\n",
        "!pip install -r requirements-colab.txt\n",
        "\n",
        "!mkdir examples\n",
        "!cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/ocr/examples/Hello.png\n",
        "!cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/ocr/examples/Hello_cursive.png\n",
        "!cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/ocr/examples/Red.png\n",
        "!cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/ocr/examples/sentence.png\n",
        "!cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/ocr/examples/i_love_you.png\n",
        "!cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/ocr/examples/merrychristmas.png\n",
        "!cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/ocr/examples/Rock.png\n",
        "!cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/ocr/examples/Bob.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUvPtiHXql1T"
      },
      "source": [
        "## 패키지 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iuvf-UtDql1U"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrMhVW2-ql1U"
      },
      "source": [
        "## 이미지 파일 업로드 UI 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUlWlb4lql1U"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# Handwritten Image OCR\")\n",
        "    image = gr.Image(label=\"Handwritten image file\")\n",
        "    output = gr.Textbox(label=\"Output Box\")\n",
        "    convert_btn = gr.Button(\"Convert\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLgwNlKAql1U"
      },
      "outputs": [],
      "source": [
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpgNkpVdql1U"
      },
      "outputs": [],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_LzOvI5ql1U"
      },
      "source": [
        "## TrOCR 추론기 클래스 구현하기\n",
        "TrOCR 추론기 클래스는 TrOCR 모델 및 processor 초기화와 추론 작업을 수행하는 클래스입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpaoTXmKql1U"
      },
      "outputs": [],
      "source": [
        "class TrOCRInferencer:\n",
        "    def __init__(self):\n",
        "        print(\"[INFO] Initialize TrOCR Inferencer.\")\n",
        "        self.processor = TrOCRProcessor.from_pretrained(\n",
        "            \"microsoft/trocr-base-handwritten\"\n",
        "        )\n",
        "        self.model = VisionEncoderDecoderModel.from_pretrained(\n",
        "            \"microsoft/trocr-base-handwritten\"\n",
        "        )\n",
        "\n",
        "    def inference(self, image: Image) -> str:\n",
        "        \"\"\"Inference using model.\n",
        "\n",
        "        It is performed as a procedure of preprocessing - inference - postprocessing.\n",
        "        \"\"\"\n",
        "        # preprocess\n",
        "        pixel_values = self.processor(images=image, return_tensors=\"pt\").pixel_values\n",
        "        # inference\n",
        "        generated_ids = self.model.generate(pixel_values)\n",
        "        # postprocess\n",
        "        generated_text = self.processor.batch_decode(\n",
        "            generated_ids, skip_special_tokens=True\n",
        "        )[0]\n",
        "\n",
        "        return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTKQR0sFQMl7"
      },
      "outputs": [],
      "source": [
        "inferencer = TrOCRInferencer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oFS6Yn_ql1U"
      },
      "source": [
        "## 추론 기능 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUzJF9yiql1V"
      },
      "outputs": [],
      "source": [
        "def image_to_text(image: np.ndarray) -> str:\n",
        "    image = Image.fromarray(image).convert(\"RGB\")\n",
        "    text = inferencer.inference(image)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cymoDna9ql1V"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# Handwritten Image OCR\")\n",
        "    image = gr.Image(label=\"Handwritten image file\")\n",
        "    output = gr.Textbox(label=\"Output Box\")\n",
        "    convert_btn = gr.Button(\"Convert\")\n",
        "    convert_btn.click(\n",
        "        fn=image_to_text, inputs=image, outputs=output\n",
        "    )\n",
        "\n",
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpzSMXe2ql1V"
      },
      "outputs": [],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6DVKR5dql1V"
      },
      "source": [
        "## 캔버스 UI 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4r5j6Xqql1V"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# Handwritten Image OCR\")\n",
        "    sketchpad = gr.Sketchpad(\n",
        "        label=\"Handwritten Sketchpad\",\n",
        "        shape=(600, 192),\n",
        "        brush_radius=2,\n",
        "        invert_colors=False,\n",
        "    )\n",
        "    output = gr.Textbox(label=\"Output Box\")\n",
        "    convert_btn = gr.Button(\"Convert\")\n",
        "    convert_btn.click(\n",
        "        fn=image_to_text, inputs=sketchpad, outputs=output\n",
        "    )\n",
        "\n",
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNkQWgodql1V"
      },
      "outputs": [],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_kWqLjpql1W"
      },
      "source": [
        "## 최종 App 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPlMPbmmql1W"
      },
      "outputs": [],
      "source": [
        "# Implement inferencer\n",
        "class TrOCRInferencer:\n",
        "    def __init__(self):\n",
        "        print(\"[INFO] Initialize TrOCR Inferencer.\")\n",
        "        self.processor = TrOCRProcessor.from_pretrained(\n",
        "            \"microsoft/trocr-base-handwritten\"\n",
        "        )\n",
        "        self.model = VisionEncoderDecoderModel.from_pretrained(\n",
        "            \"microsoft/trocr-base-handwritten\"\n",
        "        )\n",
        "\n",
        "    def inference(self, image: Image) -> str:\n",
        "        \"\"\"Inference using model.\n",
        "\n",
        "        It is performed as a procedure of preprocessing - inference - postprocessing.\n",
        "        \"\"\"\n",
        "        # preprocess\n",
        "        pixel_values = self.processor(images=image, return_tensors=\"pt\").pixel_values\n",
        "        # inference\n",
        "        generated_ids = self.model.generate(pixel_values)\n",
        "        # postprocess\n",
        "        generated_text = self.processor.batch_decode(\n",
        "            generated_ids, skip_special_tokens=True\n",
        "        )[0]\n",
        "\n",
        "        return generated_text\n",
        "\n",
        "inferencer = TrOCRInferencer()\n",
        "\n",
        "\n",
        "# Implement event function\n",
        "def image_to_text(image: np.ndarray) -> str:\n",
        "    image = Image.fromarray(image).convert(\"RGB\")\n",
        "    text = inferencer.inference(image)\n",
        "    return text\n",
        "\n",
        "\n",
        "# Implement app\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# Handwritten Image OCR\")\n",
        "    with gr.Tab(\"Image upload\"):\n",
        "        image = gr.Image(label=\"Handwritten image file\")\n",
        "        output = gr.Textbox(label=\"Output Box\")\n",
        "        convert_btn = gr.Button(\"Convert\")\n",
        "        convert_btn.click(\n",
        "            fn=image_to_text, inputs=image, outputs=output\n",
        "        )\n",
        "\n",
        "        gr.Markdown(\"## Image Examples\")\n",
        "        gr.Examples(\n",
        "            examples=[\n",
        "                os.path.join(os.getcwd(), \"examples/Hello.png\"),\n",
        "                os.path.join(os.getcwd(), \"examples/Hello_cursive.png\"),\n",
        "                os.path.join(os.getcwd(), \"examples/Red.png\"),\n",
        "                os.path.join(os.getcwd(), \"examples/sentence.png\"),\n",
        "                os.path.join(os.getcwd(), \"examples/i_love_you.png\"),\n",
        "                os.path.join(os.getcwd(), \"examples/merrychristmas.png\"),\n",
        "                os.path.join(os.getcwd(), \"examples/Rock.png\"),\n",
        "                os.path.join(os.getcwd(), \"examples/Bob.png\"),\n",
        "            ],\n",
        "            inputs=image,\n",
        "            outputs=output,\n",
        "            fn=image_to_text,\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Drawing\"):\n",
        "        sketchpad = gr.Sketchpad(\n",
        "            label=\"Handwritten Sketchpad\",\n",
        "            shape=(600, 192),\n",
        "            brush_radius=2,\n",
        "            invert_colors=False,\n",
        "        )\n",
        "        output = gr.Textbox(label=\"Output Box\")\n",
        "        convert_btn = gr.Button(\"Convert\")\n",
        "        convert_btn.click(\n",
        "            fn=image_to_text, inputs=sketchpad, outputs=output\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiIcirUoql1W"
      },
      "outputs": [],
      "source": [
        "# App 실행\n",
        "app.launch(inline=False, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjfgny1Hql1W"
      },
      "outputs": [],
      "source": [
        "app.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPM7HBfDql1W"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}